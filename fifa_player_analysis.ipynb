{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6b6387",
   "metadata": {},
   "source": [
    "# FIFA Player Analysis and Prediction using RNN\n",
    "\n",
    "This notebook implements an advanced player analysis and prediction system using Recurrent Neural Networks (RNN) with TensorFlow. We'll analyze FIFA player data to predict future performance based on current statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df5a0eb",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Let's import all the necessary libraries for our project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b954d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf8982",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing\n",
    "\n",
    "Let's load the FIFA players dataset and perform initial preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc50de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('data/players_20.csv')\n",
    "\n",
    "# Select relevant features\n",
    "features = ['age', 'overall', 'potential', 'value_eur', 'wage_eur',\n",
    "           'pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic']\n",
    "\n",
    "# Clean and prepare data\n",
    "df['value_eur'] = df['value_eur'] / 1000000  # Convert to millions\n",
    "df['wage_eur'] = df['wage_eur'] / 1000  # Convert to thousands\n",
    "\n",
    "# Remove any missing values\n",
    "df = df[features].dropna()\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bdb004",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "Let's analyze the relationships between different player attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98260084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Heatmap of Player Attributes')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create distribution plots\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(data=df, x='overall')\n",
    "plt.title('Distribution of Overall Ratings')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(data=df, x='potential')\n",
    "plt.title('Distribution of Potential Ratings')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(data=df, x='value_eur')\n",
    "plt.title('Distribution of Player Values (Millions €)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create scatter plots\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.scatterplot(data=df, x='age', y='overall')\n",
    "plt.title('Age vs Overall Rating')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.scatterplot(data=df, x='potential', y='value_eur')\n",
    "plt.title('Potential vs Value')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.scatterplot(data=df, x='overall', y='wage_eur')\n",
    "plt.title('Overall Rating vs Wage')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35780652",
   "metadata": {},
   "source": [
    "## 4. Data Preparation for RNN\n",
    "\n",
    "Let's prepare our data for the RNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b6539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df[['age', 'overall', 'potential', 'value_eur']].values\n",
    "y = df[['overall', 'potential', 'value_eur']].values\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_scaled = scaler.fit_transform(y)\n",
    "\n",
    "# Create sequences for RNN\n",
    "def create_sequences(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# Create sequences\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb91780",
   "metadata": {},
   "source": [
    "## 5. Building RNN Model\n",
    "\n",
    "Let's create our advanced RNN model with 6 hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7e2fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the RNN model\n",
    "model = Sequential([\n",
    "    # 1st LSTM layer\n",
    "    LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # 2nd LSTM layer\n",
    "    LSTM(96, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # 3rd LSTM layer\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # 4th LSTM layer\n",
    "    LSTM(48, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # 5th LSTM layer\n",
    "    LSTM(32, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # 6th LSTM layer\n",
    "    LSTM(24, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Dense layers with different activation functions\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(48, activation='elu'),\n",
    "    Dense(32, activation='selu'),\n",
    "    Dense(24, activation='tanh'),\n",
    "    Dense(16, activation='swish'),\n",
    "    Dense(8, activation='sigmoid'),\n",
    "    \n",
    "    # Output layer\n",
    "    Dense(3, activation='linear')  # 3 outputs: overall, potential, value\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2a9057",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "\n",
    "Let's train our model with early stopping and learning rate reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dab998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot MAE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Model MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ee8bf9",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "\n",
    "Let's evaluate our model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81610da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_original = scaler.inverse_transform(y_pred)\n",
    "y_test_original = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = np.mean(np.abs(y_pred_original - y_test_original), axis=0)\n",
    "mse = np.mean((y_pred_original - y_test_original)**2, axis=0)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Mean Absolute Error:\")\n",
    "print(f\"Overall: {mae[0]:.2f}\")\n",
    "print(f\"Potential: {mae[1]:.2f}\")\n",
    "print(f\"Value: {mae[2]:.2f}M €\")\n",
    "\n",
    "print(\"\\nRoot Mean Square Error:\")\n",
    "print(f\"Overall: {rmse[0]:.2f}\")\n",
    "print(f\"Potential: {rmse[1]:.2f}\")\n",
    "print(f\"Value: {rmse[2]:.2f}M €\")\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Overall Rating\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(y_test_original[:, 0], y_pred_original[:, 0], alpha=0.5)\n",
    "plt.plot([y_test_original[:, 0].min(), y_test_original[:, 0].max()], \n",
    "         [y_test_original[:, 0].min(), y_test_original[:, 0].max()], \n",
    "         'r--', lw=2)\n",
    "plt.xlabel('Actual Overall')\n",
    "plt.ylabel('Predicted Overall')\n",
    "plt.title('Overall Rating: Actual vs Predicted')\n",
    "\n",
    "# Potential\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(y_test_original[:, 1], y_pred_original[:, 1], alpha=0.5)\n",
    "plt.plot([y_test_original[:, 1].min(), y_test_original[:, 1].max()], \n",
    "         [y_test_original[:, 1].min(), y_test_original[:, 1].max()], \n",
    "         'r--', lw=2)\n",
    "plt.xlabel('Actual Potential')\n",
    "plt.ylabel('Predicted Potential')\n",
    "plt.title('Potential: Actual vs Predicted')\n",
    "\n",
    "# Value\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(y_test_original[:, 2], y_pred_original[:, 2], alpha=0.5)\n",
    "plt.plot([y_test_original[:, 2].min(), y_test_original[:, 2].max()], \n",
    "         [y_test_original[:, 2].min(), y_test_original[:, 2].max()], \n",
    "         'r--', lw=2)\n",
    "plt.xlabel('Actual Value (M €)')\n",
    "plt.ylabel('Predicted Value (M €)')\n",
    "plt.title('Value: Actual vs Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6be7624",
   "metadata": {},
   "source": [
    "## 8. Save Model\n",
    "\n",
    "Let's save our trained model for use in the Flask application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81da55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('model/fifa_player_model.h5')\n",
    "\n",
    "# Save the scaler\n",
    "with open('model/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Model and scaler saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
